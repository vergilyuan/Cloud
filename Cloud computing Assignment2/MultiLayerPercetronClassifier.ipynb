{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries and setup the environment for matplotlib\n",
    "%matplotlib inline\n",
    "import findspark\n",
    "import time\n",
    "import pandas as pd\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pyspark.sql.types import DoubleType,IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "def MLPClassifier(training_data, test_data,layers, Iter, size, features):\n",
    "    start = time.time()\n",
    "    \n",
    "    labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(training_data)\n",
    "    featureIndexer =VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\")   \n",
    "    labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",labels=labelIndexer.labels)\n",
    "    \n",
    "    # Multi-layer perceptron classifier \n",
    "    NN=MultilayerPerceptronClassifier(labelCol=\"indexedLabel\", featuresCol=features,\\\n",
    "    maxIter=Iter, layers=layers, blockSize=size, seed=1234)\n",
    "    # Training model\n",
    "    pipeline = Pipeline(stages=[labelIndexer,NN,labelConverter])\n",
    "    model = pipeline.fit(training_data)\n",
    "    # Prediction\n",
    "    predictions = model.transform(test_data)\n",
    "    #predictions.show()\n",
    "    # Accuracy\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "            labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(accuracy)\n",
    "\n",
    "    end = time.time()\n",
    "    runtime=round(end - start, 2)\n",
    "    print('Time: {}s'.format(runtime))\n",
    "    \n",
    "    return accuracy,runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_reduction(training_data,test_data,num):\n",
    "    start = time.time() # time counting\n",
    "    pca = PCA(k=num, inputCol='features', outputCol='pca') #PCA implementing\n",
    "    model = pca.fit(training_data)\n",
    "    recontructed_training_data = model.transform(training_data).select('label','features','pca')\n",
    "    recontructed_test_data = model.transform(test_data).select('label','features','pca')\n",
    "    end = time.time()\n",
    "    print('Explained Variance: {}, Time: {}s'.format(round(model.explainedVariance.sum(),3), round(end - start, 2)))\n",
    "    return recontructed_training_data, recontructed_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark Machine Learning MLP Classifier\") \\\n",
    "    .getOrCreate()\n",
    "start = time.time()\n",
    "\n",
    "test_datafile= \"Test-label-28x28.csv\"\n",
    "train_datafile = \"Train-label-28x28.csv\"\n",
    "\n",
    "\n",
    "test_df = spark.read.csv(test_datafile,header=False,inferSchema=\"true\")\n",
    "train_df = spark.read.csv(train_datafile,header=False,inferSchema=\"true\")\n",
    "\n",
    "print('Number of test data: ',test_df.count())\n",
    "print('Number of training data: ',train_df.count())\n",
    "\n",
    "# Give header to the column\n",
    "assembler = VectorAssembler(inputCols=test_df.columns[1:],\n",
    "    outputCol=\"features\")\n",
    "test_data = assembler.transform(test_df).select(test_df[0].alias('label'),\"features\")\n",
    "training_data = assembler.transform(train_df).select(train_df[0].alias('label'),\"features\")\n",
    "data = training_data.union(test_data)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print('Time: {}s'.format(round(end - start, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA dimensionality reduction\n",
    "k=50\n",
    "training_data_pca,test_data_pca=PCA_reduction(training_data,test_data,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layer size analysis\n",
    "timeList=list()\n",
    "accuracyList=list()\n",
    "\n",
    "\n",
    "Iter=100\n",
    "block_size=128\n",
    "features='pca'\n",
    "\n",
    "for num in range(50,110,10):\n",
    "    layers = [k,num,10]\n",
    "    a,t=MLPClassifier(training_data_pca, test_data_pca,layers,Iter,block_size,features)\n",
    "    timeList.append(t)\n",
    "    accuracyList.append(a)\n",
    "    \n",
    "# Plot\n",
    "x=np.arange(50,110,10)\n",
    "plt.title( 'Hidden layer size VS Accuracy')  \n",
    "plt.ylabel('Accuracy',fontsize=15)\n",
    "plt.xlabel('Hidden layer size',fontsize=15)\n",
    "plt.plot(x,np.array(accuracyList))\n",
    "plt.show()\n",
    "\n",
    "x=np.arange(50,110,10)\n",
    "plt.title( 'Hidden layer size VS Running Time')  \n",
    "plt.ylabel('Running time',fontsize=15)\n",
    "plt.xlabel('Hidden layer size',fontsize=15)\n",
    "plt.plot(x,np.array(timeList))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block size analysis\n",
    "timeList=list()\n",
    "accuracyList=list()\n",
    "\n",
    "layers = [k,50,10]\n",
    "Iter=100\n",
    "block_size=128\n",
    "features='pca'\n",
    "\n",
    "for num in range(10,140,10):\n",
    "    \n",
    "    a,t=MLPClassifier(training_data_pca, test_data_pca,layers,Iter,num,features)\n",
    "    timeList.append(t)\n",
    "    accuracyList.append(a)\n",
    "    \n",
    "# Plot\n",
    "x=np.arange(10,140,10)\n",
    "plt.title( 'BlockSize VS Accuracy')  \n",
    "plt.ylabel('Accuracy',fontsize=15)\n",
    "plt.xlabel('BlockSize',fontsize=15)\n",
    "plt.plot(x,np.array(accuracyList))\n",
    "plt.show()\n",
    "\n",
    "x=np.arange(10,140,10)\n",
    "plt.title( 'BlockSize VS Running Time')  \n",
    "plt.ylabel('Running time',fontsize=15)\n",
    "plt.xlabel('BlockSize',fontsize=15)\n",
    "plt.plot(x,np.array(timeList))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration number analysis\n",
    "timeList=list()\n",
    "accuracyList=list()\n",
    "\n",
    "layers = [k,50,10]\n",
    "block_size=128\n",
    "features='pca'\n",
    "\n",
    "for num in range(10,101,10):\n",
    "    \n",
    "    a,t=MLPClassifier(training_data_pca, test_data_pca,layers,num,block_size,features)\n",
    "    timeList.append(t)\n",
    "    accuracyList.append(a)\n",
    "    \n",
    "# Plot\n",
    "x=np.arange(10,101,10)\n",
    "plt.title( 'Number of Iteration VS Accuracy')  \n",
    "plt.ylabel('Accuracy',fontsize=15)\n",
    "plt.xlabel('Number of Iteration',fontsize=15)\n",
    "plt.plot(x,np.array(accuracyList))\n",
    "plt.show()\n",
    "\n",
    "x=np.arange(10,101,10)\n",
    "plt.title( 'Number of Iteration VS Running Time')  \n",
    "plt.ylabel('Running time',fontsize=15)\n",
    "plt.xlabel('Number of Iteration',fontsize=15)\n",
    "plt.plot(x,np.array(timeList))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
